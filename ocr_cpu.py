# -*- coding: utf-8 -*-
"""Ocr_Cpu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pS0zwxYggjTDDL0l8TAUUxU4xfVZRn6K
"""

# prompt: create cpu based dnn ocr model that runs in real time processing using tesseracts lstm using images and videos as input and plain text as output
!apt-get install tesseract-ocr
!pip install opencv-python pytesseract
from google.colab.patches import cv2_imshow

import cv2
import pytesseract
import time

def process_image(image_path):
  """
  Processes an image and returns the extracted text.
  """
  img = cv2.imread(image_path)
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  text = pytesseract.image_to_string(gray)
  return text

def process_video(video_path):
  """
  Processes a video frame by frame and prints the extracted text in real-time.
  """
  cap = cv2.VideoCapture(video_path)
  if not cap.isOpened():
    print("Error opening video stream or file")
    return

  while cap.isOpened():
    ret, frame = cap.read()
    if ret:
      start_time = time.time()
      text = pytesseract.image_to_string(frame)
      end_time = time.time()
      print(text)
      print("Processing time: {:.2f} seconds".format(end_time - start_time))

      cv2_imshow(frame)
      if cv2.waitKey(25) & 0xFF == ord('q'):
        break
    else:
      break

  cap.release()
  cv2.destroyAllWindows()

# Example usage for image processing
image_text = process_image('/content/drive/MyDrive/Colab Notebooks/WhatsApp Image 2024-08-27 at 12.05.09_fa58bcee.jpg')
print("Text from image:\n", image_text)

# Example usage for video processing

process_video('/content/drive/MyDrive/Colab Notebooks/Welcome to PowerPoint.mp4')

# prompt: create Gpu based ocr model that runs in real time processing using CUDA using images and videos as input and plain text as output

!pip install torch torchvision torchaudio

import torch
import cv2
import time
from google.colab.patches import cv2_imshow

# Check if CUDA is available
if torch.cuda.is_available():
  device = torch.device('cuda')
  print("CUDA is available. Using GPU for processing.")
else:
  device = torch.device('cpu')
  print("CUDA is not available. Using CPU for processing.")

# Load the pre-trained OCR model (replace with your desired model)
model = torch.hub.load('ultralytics/yolov5', 'custom', path='path_to_your_ocr_model.pt')  # Replace with your model path
model.to(device)
model.eval()

def process_image(image_path):
  """
  Processes an image using the OCR model and returns the extracted text.
  """
  img = cv2.imread(image_path)
  # Preprocess the image (resize, normalize, etc. as required by your model)
  # ...

  # Perform inference
  with torch.no_grad():
    results = model(img)

  # Extract text from the results
  text = ""
  for detection in results.xyxy[0]:
    # Assuming your model outputs bounding boxes and text labels
    x1, y1, x2, y2, conf, cls = detection
    text += results.names[int(cls)] + " "  # Replace with your text extraction logic

  return text

def process_video(video_path):
  """
  Processes a video frame by frame using the OCR model and prints the extracted text in real-time.
  """
  cap = cv2.VideoCapture(video_path)
  if not cap.isOpened():
    print("Error opening video stream or file")
    return

  while cap.isOpened():
    ret, frame = cap.read()
    if ret:
      start_time = time.time()

      # Preprocess the frame (resize, normalize, etc. as required by your model)
      # ...

      # Perform inference
      with torch.no_grad():
        results = model(frame)

      # Extract text from the results
      text = ""
      for detection in results.xyxy[0]:
        # Assuming your model outputs bounding boxes and text labels
        x1, y1, x2, y2, conf, cls = detection
        text += results.names[int(cls)] + " "  # Replace with your text extraction logic

      end_time = time.time()
      print(text)
      print("Processing time: {:.2f} seconds".format(end_time - start_time))

      cv2_imshow(frame)
      if cv2.waitKey(25) & 0xFF == ord('q'):
        break
    else:
      break

  cap.release()
  cv2.destroyAllWindows()

# Example usage for image processing
image_text = process_image('/content/drive/MyDrive/Colab Notebooks/WhatsApp Image 2024-08-27 at 12.05.09_fa58bcee.jpg')
print("Text from image:\n", image_text)

# Example usage for video processing
process_video('/content/drive/MyDrive/Colab Notebooks/Welcome to PowerPoint.mp4')